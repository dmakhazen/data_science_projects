![image](https://github.com/dmakhazen/portfolio/assets/107398428/db64c2cd-b2ed-4140-b89f-0472fc2bcfbd)


# Bank customer churn

Результат:
- [Jupyter_notebook](https://github.com/dmakhazen/portfolio/tree/main/bank_customer_churn/bank_customer_churn_reviewed.ipynb)
- [Google Colab](https://colab.research.google.com/drive/1pATt4qs5q-4rMflkhMwoNuNqYCM_Ikhh?usp=sharing)

## Описание проекта

**Описание проблемы**

Из «South Park Bank» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых. Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

**Цель**

Моя цель состоит в том, чтобы разработать модель, способную предсказать, уйдет ли клиент из нашего банка в ближайшем будущем или нет. Я стремлюсь построить модель с высоким значением F1-меры, которая является важной метрикой для нашего проекта. Необходимо достичь значения F1-меры не менее 0.59, чтобы успешно завершить проект. Кроме того, я также буду оценивать AUC-ROC и сравнивать его со значением F1-меры.

**Источник данных:** [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## Ключевые особенности
- Борьба с дисбалансом классов

## Инструменты, навыки

Инструменты:
- Pandas
- Matplotlib
- Sklearn

Навыки:
- Обработка табличными данными
- Изменения баланса классов
- Построение ML модели

## Результат

**Модель**

- Обучил итоговую модель на основе RandomForestClassifier
- Метрики модели
  1. **F1 = 0.6124**
  2. accuracy = 0.8285
  3. auc_roc = 0.8574
  4. precision = 0.566
  5. recall = 0.665
  
**Выводы**
- На данной выборке самый лучший результат дает широкий подбор гиперпараметров и балансировка классов в аргументе к модели. 
- Синтетическое изменение баланса классов в данной работе повредило F1-мере модели

**Дальнейшее развитие модели**
- Хотя данных достаточно для обучения (10к строк), дополнительный сбор новых данных помог бы улучшить модель
- В работе доступно для модели 11 признаков, неплохо было бы расширить их количество, например уточнить место жительства, вид работы, должность, данные родственников и многое другое
- Акцент в работе сделан на борьбе с дисбалансов классов, а не на выборе модели. Если взять в качестве основной модели - какой-либо градиентный бустинг (либо перебрать больше моделей), метрики возможно улучшить
- После появления новых признаков и моделей, стоит оценить feature_importance и дальше работать над обработкой признаков: убрать лишние, преобразовать имеющиеся
